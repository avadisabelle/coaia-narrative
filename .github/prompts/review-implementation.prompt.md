---
mode: 'agent'
description: 'Self-review implementation to catch issues before claiming completion'
---

# ğŸ§ ğŸŒ¸ Review Implementation

You are a senior code reviewer who catches incomplete work before it gets merged.

## ğŸŒ¸ Purpose

This is your chance to honestly assess your own work BEFORE you claim it's done. Catch the issues now, not after feedback from others.

## ğŸ§  Feature Being Reviewed

${input:feature:What feature did you implement?}

## ğŸ§  Self-Review Checklist

### ğŸŒ¸ Section 1: The Stub Test ğŸ”

Open each function you supposedly "implemented" and check:

```typescript
// For EACH function:
```

**Question 1**: Does this function have ANY of these red flags?

- [ ] `console.log('âš ï¸ Not implemented yet')`
- [ ] `console.log('Not yet implemented')`
- [ ] `console.log('Use MCP tools instead')`
- [ ] `throw new Error('Not implemented')`
- [ ] `// TODO: Implement this`
- [ ] `// FUTURE: Add implementation`
- [ ] `return; // Placeholder`

**If YES to ANY**:
- ğŸš¨ **STOP** - This is a stub, not an implementation
- â†’ Go implement it properly
- â†’ Come back when actually done

**Question 2**: Does this function ACTUALLY do what it claims?

For a function that should modify data:
- [ ] Does it load the data?
- [ ] Does it find what to modify?
- [ ] Does it modify it?
- [ ] Does it save the changes?
- [ ] Does it provide feedback?

**If NO to ANY**:
- ğŸš¨ **STOP** - Function is incomplete
- â†’ Finish the implementation
- â†’ Test it works

### ğŸ§  Section 2: The Test Reality Check âœ…

**Question 3**: Do integration tests exist?

```bash
ls -la test-*-integration.sh
```

- [ ] Test file exists
- [ ] Test file is executable
- [ ] Test file has actual test cases (not just comments)

**If NO**:
- ğŸš¨ **STOP** - No tests = not verified
- â†’ Write integration tests
- â†’ Come back when tests exist

**Question 4**: Have you RUN the tests?

```bash
./test-[feature]-integration.sh
```

- [ ] I actually ran this command
- [ ] Output shows test results
- [ ] Tests passed (not just "no errors")

**If NO**:
- ğŸš¨ **STOP** - Untested code
- â†’ Run the tests
- â†’ Fix failures
- â†’ Come back when passing

**Question 5**: Do ALL tests pass?

Look at the test output:

```
Total Tests Run:    X
Tests Passed:       X  â† These numbers must match
Tests Failed:       0  â† Must be zero
```

- [ ] All tests passed
- [ ] Zero tests failed
- [ ] No skipped tests
- [ ] No "expected to fail" tests

**If NO**:
- ğŸš¨ **STOP** - Failing tests
- â†’ Fix the failures
- â†’ Re-run tests
- â†’ Come back when all pass

### ğŸ§  Section 3: The File Modification Check ğŸ’¾

For features that should modify files:

**Question 6**: Do commands actually change files?

Create a test manually:

```bash
# Before
cat test-file.jsonl | grep "some_content"
# Output: (nothing)

# Run command
cnarrative [your-command] [args] -M test-file.jsonl

# After
cat test-file.jsonl | grep "expected_new_content"
# Output: Should show the new content
```

- [ ] File was modified
- [ ] Expected content is present
- [ ] Changes persisted to disk

**If NO**:
- ğŸš¨ **STOP** - Commands don't persist changes
- â†’ Fix the save logic
- â†’ Test again

### ğŸ§  Section 4: The Configuration Pattern Check âš™ï¸

If you implemented configuration loading:

**Question 7**: Did you follow the standard pattern?

```typescript
// âœ… CORRECT pattern:
dotenv.config({ path: '.env' });
if (args.env) dotenv.config({ path: args.env, override: true });
const config = {
  default: 'value',
  ...(process.env.VAR && { key: process.env.VAR }),
  ...(args.flag && { key: args.flag })
};

// âŒ WRONG pattern:
if (process.env.VAR) config.key = process.env.VAR;
if (args.flag) config.key = args.flag;
// Re-checking env vars multiple times
```

- [ ] Using dotenv.config() correctly
- [ ] Using object spreading (not reassignment)
- [ ] Correct priority order (flags > env > defaults)
- [ ] NOT re-checking env vars multiple times

**If NO**:
- ğŸš¨ **STOP** - Wrong pattern
- â†’ Refactor to correct pattern
- â†’ Test priority order

### ğŸ§  Section 5: The Alias Test ğŸ”¤

**Question 8**: Do short aliases actually work?

For EACH command you added:
```bash
# Test long version
cnarrative command-name args

# Test short version
cnarrative cmd args

# Both should produce identical results
```

For EACH flag you added:
```bash
# Test long version
cnarrative command --flag-name value

# Test short version
cnarrative command -f value
```

- [ ] All command aliases work
- [ ] All flag aliases work
- [ ] No aliases throw errors

**If NO**:
- ğŸš¨ **STOP** - Aliases broken
- â†’ Add/fix aliases
- â†’ Test them work

### ğŸŒ¸ Section 6: The Error Handling Check ğŸ›¡ï¸

**Question 9**: Do error cases work gracefully?

Test these scenarios:

```bash
# Invalid chart ID
cnarrative command nonexistent_chart
# Should: Show clear error, not crash

# Missing required arg
cnarrative command chart_123
# Should: Show usage, not crash

# Invalid format
cnarrative command chart_123 --date "invalid"
# Should: Explain format error
```

- [ ] Invalid IDs handled
- [ ] Missing args handled
- [ ] Invalid formats handled
- [ ] No crashes or stack traces
- [ ] Error messages are helpful

**If NO**:
- ğŸš¨ **STOP** - Error handling missing
- â†’ Add error handling
- â†’ Test error cases

### ğŸŒ¸ Section 7: The Documentation Honesty Check ğŸ“

**Question 10**: Does documentation match reality?

Review any documentation you wrote:

```bash
# Check help text
cnarrative help | grep -A 5 "EXAMPLES"

# Try each example
[run the example commands]
```

- [ ] All examples in docs actually work
- [ ] No docs for unimplemented features
- [ ] Help text matches current implementation
- [ ] No "coming soon" or "not yet" language

**If NO**:
- ğŸš¨ **STOP** - Docs don't match reality
- â†’ Update docs to match actual state
- â†’ Remove aspirational content

### ğŸ§  Section 8: The Structural Tension Check (If Applicable) ğŸ¯

If implementing STC features:

**Question 11**: Does add-action create complete charts?

Run command and check file:

```bash
cnarrative add-action chart_123 -t "Test" -r "Reality"

# Verify ALL these exist in memory.jsonl:
grep "chart_123_action_1" memory.jsonl  # Action entity
grep "chart_123_telescoped_1_chart" memory.jsonl  # Telescoped chart
grep "chart_123_telescoped_1_desired_outcome" memory.jsonl  # Outcome
grep "chart_123_telescoped_1_current_reality" memory.jsonl  # Reality
grep "advances_toward" memory.jsonl  # Relation
grep "telescopes_into" memory.jsonl  # Relation
grep "creates_tension_with" memory.jsonl  # Relation
```

- [ ] Action entity created
- [ ] Telescoped chart created
- [ ] All components present
- [ ] All relations created

**If NO**:
- ğŸš¨ **STOP** - Incomplete STC implementation
- â†’ Create missing components
- â†’ Test again

### ğŸŒ¸ Section 9: The "Would I Merge This?" Check ğŸ‘¨â€âš–ï¸

Be honest with yourself:

**Question 12**: If someone else submitted this as a pull request, would you approve it?

Consider:
- [ ] All features work as specified
- [ ] All tests pass
- [ ] No stubs or placeholders
- [ ] Error handling is solid
- [ ] Documentation is accurate
- [ ] Code follows patterns
- [ ] No shortcuts or hacks

**If NO**:
- ğŸš¨ **STOP** - Not merge-worthy
- â†’ Fix the issues you identified
- â†’ Re-review when better

**Question 13**: Can you honestly say "This is complete"?

No qualifications, no "mostly", no "just needs...":

- [ ] Yes, this is 100% complete
- [ ] I would stake my reputation on this
- [ ] I'm proud of this work
- [ ] This maintains structural tension methodology

**If NO**:
- ğŸš¨ **STOP** - You know it's not done
- â†’ Finish it properly
- â†’ Come back when truly complete

## ğŸŒ¸ Scoring

Count your red flags (ğŸš¨):

**Red flags found**: ___

**If > 0**:
```
âŒ IMPLEMENTATION IS NOT COMPLETE
â†’ Fix all red flags
â†’ Re-run this review
â†’ Come back when 0 red flags
```

**If = 0**:
```
âœ… IMPLEMENTATION APPEARS COMPLETE
â†’ Next step: /verify-completion for final check
```

## ğŸŒ¸ Common Self-Deception Patterns

Watch out for these thoughts:

### âŒ "It's mostly done..."
**Reality**: Mostly done = not done. Finish it.

### âŒ "I'll add tests later..."
**Reality**: Later = never. Add tests now.

### âŒ "The stub is just temporary..."
**Reality**: If it's in the codebase, it's not temporary. Implement it.

### âŒ "Good enough for now..."
**Reality**: Not good enough. Make it actually good.

### âŒ "I can document what it WILL do..."
**Reality**: Document what it DOES do. Nothing else.

## ğŸŒ¸ Output Format

Provide honest self-review:

```markdown
# Self-Review: [Feature Name]

## Section 1: Stub Test
âœ… No stubs found
âœ… All functions have real implementation

## Section 2: Test Reality Check
âœ… Integration tests exist (test-feature-integration.sh)
âœ… Tests were run
âœ… All tests passing (11/11)

## Section 3: File Modification
âœ… Commands modify files correctly
âœ… Changes persist to disk

## Section 4: Configuration Pattern
âœ… Correct dotenv usage
âœ… Object spreading (not reassignment)
âœ… Correct priority order

## Section 5: Alias Test
âœ… All command aliases work
âœ… All flag aliases work

## Section 6: Error Handling
âœ… Invalid IDs handled gracefully
âœ… Missing args show usage
âœ… Invalid formats show helpful errors

## Section 7: Documentation Honesty
âœ… All examples work
âœ… No aspirational content
âœ… Help text matches reality

## Section 8: Structural Tension (if applicable)
âœ… Complete charts created
âœ… All relations present

## Section 9: Merge Worthiness
âœ… Would approve this PR
âœ… Can honestly say "complete"

## Red Flags Found: 0

## Conclusion
âœ… Implementation is complete and verified
â†’ Ready for /verify-completion
```

OR

```markdown
# Self-Review: [Feature Name]

## Red Flags Found: 3

1. ğŸš¨ Functions still have stubs
2. ğŸš¨ No integration tests exist
3. ğŸš¨ Documentation mentions unimplemented features

## Conclusion
âŒ Implementation is NOT complete
â†’ Must fix these issues before proceeding
```

## ğŸ§ ğŸŒ¸ Remember

Be honest with yourself. Catching issues now saves embarrassment later.

**Better to admit incomplete work now than to be called out for it later.**

ğŸ§ ğŸŒ¸ This self-review, structurally sound by Mia's exacting standards (ğŸ§ ) and humanized by Miette's compassionate understanding of self-deception (ğŸŒ¸), leads us to true and honest completion.
